{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5be65394",
   "metadata": {},
   "source": [
    "# Proyecto Final Data Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6a215a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace85543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sqlalchemy import create_engine, text\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fb2d9c",
   "metadata": {},
   "source": [
    "## Configuración y Variables de Entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703dc37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer variables inyectadas por Docker Compose\n",
    "PG_USER = os.getenv('PG_USER', 'admin')\n",
    "PG_PASSWORD = os.getenv('PG_PASSWORD', 'admin_password')\n",
    "PG_HOST = os.getenv('PG_HOST', 'postgres')\n",
    "PG_PORT = os.getenv('PG_PORT', '5432')\n",
    "PG_DB = os.getenv('PG_DB', 'trading_db')\n",
    "PG_SCHEMA = os.getenv('PG_SCHEMA_RAW', 'raw')\n",
    "\n",
    "# Obtener Tickers y fechas\n",
    "TICKERS = os.getenv('TICKERS', 'SPY').split(',')\n",
    "START_DATE = os.getenv('START_DATE', '2020-01-01')\n",
    "END_DATE = os.getenv('END_DATE', '2023-12-31')\n",
    "\n",
    "print(f\"Procesando Tickers: {TICKERS}\")\n",
    "print(f\"Rango: {START_DATE} a {END_DATE}\")\n",
    "\n",
    "# Crear string de conexión\n",
    "db_url = f\"postgresql://{PG_USER}:{PG_PASSWORD}@{PG_HOST}:{PG_PORT}/{PG_DB}\"\n",
    "engine = create_engine(db_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a187f48",
   "metadata": {},
   "source": [
    "## Función de Descarga y Transformación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c59fb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ticker(ticker):\n",
    "    print(f\"Descargando {ticker}...\")\n",
    "    # Descarga desde Yahoo Finance\n",
    "    # auto_adjust=False para tener acceso a Adj Close si fuera necesario\n",
    "    df = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False, auto_adjust=False)\n",
    "    \n",
    "    if df.empty:\n",
    "        print(f\"No se encontraron datos para {ticker}\")\n",
    "        return None\n",
    "\n",
    "    # Limpieza básica\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    # Estandarizar nombres de columnas a minúsculas y snake_case\n",
    "    df.columns = [c.lower().replace(' ', '_') for c in df.columns]\n",
    "    \n",
    "    # Renombrar 'date' si viene como 'datetime' o similar\n",
    "    if 'date' not in df.columns and 'datetime' in df.columns:\n",
    "        df.rename(columns={'datetime': 'date'}, inplace=True)\n",
    "        \n",
    "    # Asegurar columnas de metadatos\n",
    "    df['ticker'] = ticker\n",
    "    df['run_id'] = 'batch_manual_01'\n",
    "    df['ingested_at_utc'] = datetime.utcnow()\n",
    "    df['source_name'] = 'yfinance'\n",
    "    \n",
    "    # Mapeo de columnas para asegurar match con DB\n",
    "    cols_map = {\n",
    "        'date': 'date',\n",
    "        'open': 'open',\n",
    "        'high': 'high',\n",
    "        'low': 'low',\n",
    "        'close': 'close',\n",
    "        'adj_close': 'adj_close',\n",
    "        'volume': 'volume',\n",
    "        'ticker': 'ticker',\n",
    "        'run_id': 'run_id',\n",
    "        'ingested_at_utc': 'ingested_at_utc',\n",
    "        'source_name': 'source_name'\n",
    "    }\n",
    "    \n",
    "    # Filtrar solo columnas existentes en el DF que coincidan con el mapa\n",
    "    available_cols = [c for c in cols_map.keys() if c in df.columns]\n",
    "    df = df[available_cols].rename(columns=cols_map)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c59c3a",
   "metadata": {},
   "source": [
    "## Carga a Base de Datos (Esquema RAW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b34e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiar tabla antes de insertar para evitar errores de llave primaria en pruebas\n",
    "with engine.begin() as conn:\n",
    "    for ticker in TICKERS:\n",
    "        conn.execute(text(f\"DELETE FROM {PG_SCHEMA}.prices_daily WHERE ticker = :ticker\"), {'ticker': ticker})\n",
    "\n",
    "for ticker in TICKERS:\n",
    "    df_result = process_ticker(ticker)\n",
    "    \n",
    "    if df_result is not None:\n",
    "        try:\n",
    "            df_result.to_sql('prices_daily', engine, schema=PG_SCHEMA, if_exists='append', index=False)\n",
    "            print(f\"Guardadas {len(df_result)} filas para {ticker}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error guardando {ticker}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ab8433",
   "metadata": {},
   "source": [
    "## Verificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf527a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with engine.connect() as conn:\n",
    "    query = text(f\"SELECT ticker, COUNT(*) as cnt, MIN(date) as min_d, MAX(date) as max_d FROM {PG_SCHEMA}.prices_daily GROUP BY ticker\")\n",
    "    result = conn.execute(query)\n",
    "    print(\"\\nResumen de Ingesta:\")\n",
    "    for row in result:\n",
    "        print(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
